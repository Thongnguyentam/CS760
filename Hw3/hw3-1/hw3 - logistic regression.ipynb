{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from logistic_regression import CustomeLogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_email = pd.read_csv('data/emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold1\n",
    "fold1_train = df_email[1000:]\n",
    "X_fold1 = fold1_train.drop(['Email No.', 'Prediction'], axis = 1).apply(pd.to_numeric, axis = 1)\n",
    "Y_fold1 = fold1_train['Prediction']\n",
    "\n",
    "fold1_test = df_email[0:1000]\n",
    "x_test_fold1 = fold1_test.drop(['Email No.', 'Prediction'], axis = 1).apply(pd.to_numeric, axis = 1)\n",
    "y_actual_fold1 = fold1_test['Prediction']\n",
    "\n",
    "#fold2\n",
    "fold2_train = df_email.drop(index= range(999, 2000))\n",
    "X_fold2 = fold2_train.drop(['Email No.', 'Prediction'], axis=1).apply(pd.to_numeric, axis = 1)\n",
    "Y_fold2 = fold2_train['Prediction']\n",
    "\n",
    "fold2_test = df_email[999:2000]\n",
    "x_test_fold2 = fold2_test.drop(['Email No.', 'Prediction'], axis = 1).apply(pd.to_numeric, axis = 1)\n",
    "y_actual_fold2 = fold2_test['Prediction']\n",
    "\n",
    "#fold3\n",
    "fold3_train = df_email.drop(index= range(1999, 3000))\n",
    "X_fold3 = fold3_train.drop(['Email No.', 'Prediction'], axis=1).apply(pd.to_numeric, axis = 1)\n",
    "Y_fold3 = fold3_train['Prediction']\n",
    "\n",
    "fold3_test = df_email[1999:3000]\n",
    "x_test_fold3 = fold3_test.drop(['Email No.', 'Prediction'], axis = 1).apply(pd.to_numeric, axis = 1)\n",
    "y_actual_fold3 = fold3_test['Prediction']\n",
    "\n",
    "#fold4\n",
    "fold4_train = df_email.drop(index= range(2999, 4000))\n",
    "X_fold4 = fold4_train.drop(['Email No.', 'Prediction'], axis=1).apply(pd.to_numeric, axis = 1)\n",
    "Y_fold4 = fold4_train['Prediction']\n",
    "\n",
    "fold4_test = df_email[2999:4000]\n",
    "x_test_fold4 = fold4_test.drop(['Email No.', 'Prediction'], axis = 1).apply(pd.to_numeric, axis = 1)\n",
    "y_actual_fold4 = fold4_test['Prediction']\n",
    "\n",
    "#fold5\n",
    "fold5_train = df_email.drop(index= range(3999, 5000))\n",
    "X_fold5 = fold5_train.drop(['Email No.', 'Prediction'], axis=1).apply(pd.to_numeric, axis = 1)\n",
    "Y_fold5 = fold5_train['Prediction']\n",
    "\n",
    "fold5_test = df_email[3999:5000]\n",
    "x_test_fold5 = fold5_test.drop(['Email No.', 'Prediction'], axis = 1).apply(pd.to_numeric, axis = 1)\n",
    "y_actual_fold5 = fold5_test['Prediction']\n",
    "\n",
    "# result\n",
    "res = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 0.01, epoch 400\n",
    "lr = CustomeLogisticRegression(learning_rate= 0.005)\n",
    "epoch = 1000\n",
    "metrics = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.906, 0.8687258687258688, 0.7894736842105263],\n",
       " [0.8831168831168831, 0.8669724770642202, 0.6823104693140795],\n",
       " [0.8931068931068931, 0.84765625, 0.7614035087719299],\n",
       " [0.8791208791208791, 0.841897233201581, 0.7244897959183674],\n",
       " [0.5164835164835165, 0.38441558441558443, 0.9673202614379085]]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_fold1, Y_fold1, epoch)\n",
    "pred = lr.predict(x_test_fold1)\n",
    "accuracy = accuracy_score(pred,y_actual_fold1)\n",
    "recall = recall_score(pred,y_actual_fold1)\n",
    "prec = precision_score(pred,y_actual_fold1)\n",
    "metrics.append([accuracy, recall, prec])\n",
    "#pred_train = lr.predict(X_fold1)\n",
    "#accuracy_train = accuracy_score(pred_train, Y_fold1)\n",
    "#print(accuracy_train, accuracy)\n",
    "\n",
    "lr.fit(X_fold2, Y_fold2, epoch)\n",
    "pred = lr.predict(x_test_fold2)\n",
    "accuracy = accuracy_score(pred,y_actual_fold2)\n",
    "recall = recall_score(pred,y_actual_fold2)\n",
    "prec = precision_score(pred,y_actual_fold2)\n",
    "metrics.append([accuracy, recall, prec])\n",
    "#pred_train = lr.predict(X_fold2)\n",
    "#accuracy_train = accuracy_score(pred_train, Y_fold2)\n",
    "#print(accuracy_train, accuracy)\n",
    "\n",
    "#0.877\n",
    "lr.fit(X_fold3, Y_fold3, epoch)\n",
    "pred = lr.predict(x_test_fold3)\n",
    "accuracy = accuracy_score(pred,y_actual_fold3)\n",
    "recall = recall_score(pred,y_actual_fold3)\n",
    "prec = precision_score(pred,y_actual_fold3)\n",
    "metrics.append([accuracy, recall, prec])\n",
    "#pred_train = lr.predict(X_fold3)\n",
    "#accuracy_train = accuracy_score(pred_train, Y_fold3)\n",
    "#print(accuracy_train, accuracy)\n",
    "\n",
    "#fold 4\n",
    "lr.fit(X_fold4, Y_fold4, epoch)\n",
    "pred = lr.predict(x_test_fold4)\n",
    "accuracy = accuracy_score(pred,y_actual_fold4)\n",
    "recall = recall_score(pred,y_actual_fold4)\n",
    "prec = precision_score(pred,y_actual_fold4)\n",
    "metrics.append([accuracy, recall, prec])\n",
    "#pred_train = lr.predict(X_fold4)\n",
    "#accuracy_train = accuracy_score(pred_train, Y_fold4)\n",
    "#print(accuracy_train, accuracy)\n",
    "\n",
    "lr.fit(X_fold5, Y_fold5, epoch)\n",
    "pred = lr.predict(x_test_fold5)\n",
    "accuracy = accuracy_score(pred,y_actual_fold5)\n",
    "recall = recall_score(pred,y_actual_fold5)\n",
    "prec = precision_score(pred,y_actual_fold5)\n",
    "metrics.append([accuracy, recall, prec])\n",
    "#pred_train = lr.predict(X_fold5)\n",
    "#accuracy_train = accuracy_score(pred_train, Y_fold5)\n",
    "#print(accuracy_train, accuracy)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.821936322651851"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, threshold = roc_curve(pred, y_actual_fold5)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8690973026973028"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame(metrics, columns= ['accuracy', 'recall', 'prec'])\n",
    "np.mean(metrics['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
